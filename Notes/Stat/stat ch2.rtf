{\rtf1\ansi\ansicpg1252\deff0\nouicompat\deflang1033{\fonttbl{\f0\fnil\fcharset0 Calibri;}{\f1\fnil Calibri;}{\f2\fnil\fcharset161 Calibri;}{\f3\fnil\fcharset1 Cambria Math;}}
{\*\generator Riched20 10.0.17134}{\*\mmathPr\mmathFont3\mwrapIndent1440 }\viewkind4\uc1 
\pard\sa200\sl276\slmult1\f0\fs22\lang9 2 SIMPLE PROBABILITY SAMPLES\par
2.1 Types of Probability Samples \f1\bullet  A simple random sample (SRS) of size n is a sample of n units selected from a population in such a way that every sample of size n has an equal chance of being selected.\par
\endash  The Board of Regents at a university is deciding whether or not every one of its students must have two semesters of statistics coursework in order to ful\u-1279?ll their degree requirements. The student senate selected 200 students at random from the entire student body and asked their opinion on this issue. It was found that 1% of the students sampled supported a requirement of two semesters of statistics coursework. \endash  A sample of twenty MSU instructors is selected based on the following scheme: An alphabetical list of all the instructors is prepared, then a unique number is assigned in sequence (1,2,3,...) to each instructor, and \u-1279?nally, using a random number generator, twenty instructors are randomly chosen. \bullet  A strati\u-1279?ed random sample is a sample selected by \u-1279?rst dividing the population into non-overlapping groups called strata and then taking a simple random sample within each stratum. Dividing the population into strata should be based on some criterion so that units are similar within a stratum but are di\u-1280?erent between strata.\par
\endash  The Career Services sta\u-1280? wants to know if they are adequately meeting the needs of the students they serve. They design a survey which addresses this question, and they send the survey to 50 students randomly chosen from each of the university\rquote s colleges (50 agriculture students, 50 arts and science students, 50 engineering students, etc.). \endash  A biologist is interested in estimating a deer population total in a small geographic region. The region contains two habitat types which are known to in\u-1278?uence deer abundance. From each habitat type, 10 plots are randomly selected to be surveyed. \endash  Note: Stratum sample sizes do not have to be equal. \bullet  A systematic sample is a sample in which units are selected in a \ldblquote systematic\rdblquote  pattern in the population of interest. To take a systematic sample you will need to divide the sampling frame into groups of units, randomly choose a set of starting points in the \u-1279?rst group, and then sample from every group using the same positions of the starting points.\par
\endash  You are a quality engineer at Intel and are testing the quality of newly-produced computer chips. You need to take a sample of chips and test their quality. As the chips roll o\u-1280? the production line, you decided to test every 50th chip produced starting with the third chip (i.e., sample chips 3, 53, 103, 153, ...). \bullet  Suppose the observation units in a population are grouped into non-overlapping sets called clusters. A cluster sample is a SRS of clusters.\par
\endash  You work for the Department of Agriculture and wish to determine the percentage of farmers in the United States who use organic farming techniques. It would be di\u-1277?cult and costly to collect a SRS or a systematic sample because both of these sampling designs would require visiting many individual farms that are located far from each other. A convenience sample of farmers from a single county would be\par
12\par
biased because farming practices vary from region to region. You decide to select several dozen counties from across the United States and then survey every farmer in each of these selected counties. Each county contains a cluster of farmers and data is collected on every farm within the randomly selected counties (clusters).\par
\bullet  A multistage sample is a sample acquired by successively selecting smaller groups within the population in stages. The selection process at any stage may employ any sampling design (such as a SRS or a strati\u-1279?ed sample).\par
\endash  A city o\u-1277?cial is investigating rumors about the landlord of a large apartment building\par
13\par
complex. To get an idea of the tenants\rquote  opinions about their landlord, the o\u-1277?cial takes a SRS of buildings in the complex followed by a SRS of apartments from each selected building. From each chosen apartment a resident is interviewed. \endash  A U.S. national opinion poll was taken as follows: First, the U.S. is strati\u-1279?ed into 4 regions. Then a random sample of counties was selected from each region followed by a random sample of townships within each of these counties. Finally, a random sample of households (clusters) within each township is taken.\par
2.2 Probability Sampling Designs \bullet  Suppose N is the population size. That is, there are N units in the universe or \u-1279?nite population of interest. \bullet  The N units in the universe are denoted by an index set of labels: U = \{ 1, 2, 3, ... N \} Note: Some texts will denote U = \{u1,u2,u3,...uN\}. \bullet  From this universe (or population) a sample of n units is to be taken. Let S represent a sample of n units from U. \bullet  Associated with each of the N units is a measurable value related to the population characteristic of interest. Let yi be the value associated with unit i, and the population of y-values is \{y1,y2,...,yN\}. \bullet  A point of clari\u-1279?cation is needed here. On page 28, Lohr states that S is \ldblquote a subset consisting of n of the units in U. \endash  S will only be a \lquote subset\rquote  in a strict mathematical sense if sampling is done without replacement. That is, a unit can only appear in the sample at most once. \endash  However, S will not be a \lquote subset\rquote  if sampling is done with replacement. That is, a unit can appear in the sample multiple times. \bullet  Sampling designs that are based on planned randomness are called probability samples, and a probability P(S) is assigned to every possible sample S. \bullet  The probability that unit i will be included in a sample is denoted \f2\lang1032\'f0i and is called the inclusion probability for unit i. \f1\bullet  In many sampling procedures, di\u-1280?erent units in the population have di\u-1280?erent probabilities of being included in a sample (i.e., di\u-1280?erent inclusion probabilities) that depend on either (i) the type of sampling procedure or (ii) the probabilities may be imposed by the researcher to obtain better estimates by including \ldblquote more important\rdblquote  units with higher probability. \bullet  Example: Suppose unit selections are drawn with probability proportional to unit size and that sampling is done with replacement of units.\par
\endash  The population total = 16. There are N = 5 sampling units. The \u-1279?gure shows the units, labeled 1 to 5, and the \u-1279?ve yi values.\par
14\par
\endash  Sampling plan: You are to select two units. The \u-1279?rst unit ui is selected with probability pi proportional to its size and the yi is recorded. The unit is then put back. A second unit uj is selected using the same method for selecting the \u-1279?rst unit, and its yj value is recorded. \endash  Note that the same unit can be sampled twice. This is an example of sampling with replacement. The following table describes the population.\par
1 2 3 4 5\par
yi \f3\u8722?\u8594?\f0  pi \f3\u8722?\u8594?\f0  .4 .3 .1 .1 .1 \f1\endash  The table below shows all 15 possible pairs of sampled y-values (but not ordered). E.g., (1,2) means you selected unit 1 then unit 2 or you selected unit 2 then unit 1.\par
In either case, you end up with the same sample of size 2. Note\par
15 X i=1\par
P(Si) = 1.\par
Sample Units y-values P(Sj) Calculation S1 \{1,2\} 7 , 4 0.24 (.4)(.3) + (.3)(.4) S2 \{1,3\} 7 , 0 0.08 (.4)(.1) + (.1)(.4) S3 \{1,4\} 7 , 2 0.08 (.4)(.1) + (.1)(.4) S4 \{1,5\} 7 , 3 0.08 (.4)(.1) + (.1)(.4) S5 \{2,3\} 4 , 0 0.06 (.3)(.1) + (.1)(.3) S6 \{2,4\} 4 , 2 0.06 (.3)(.1) + (.1)(.3) S7 \{2,5\} 4 , 3 0.06 (.3)(.1) + (.1)(.3) S8 \{3,4\} 0 , 2 0.02 (.1)(.1) + (.1)(.1) S9 \{3,5\} 0 , 3 0.02 (.1)(.1) + (.1)(.1) S10 \{4,5\} 2 , 3 0.02 (.1)(.1) + (.1)(.1) S11 \{1,1\} 7 , 7 0.16 (.4)(.4) S12 \{2,2\} 4 , 4 0.09 (.3)(.3) S13 \{3,3\} 0 , 0 0.01 (.1)(.1) S14 \{4,4\} 2 , 2 0.01 (.1)(.1) S15 \{5,5\} 3 , 3 0.01 (.1)(.1) The inclusion probability \f2\lang1032\'f0i is found by summing P(Si) over all samples containing unit i. Thus, the inclusion probabilities when sampling with replacement are\par
\'f01 = = .24 + .08 + .08 + .08 + .16 \'f02 = = .24 + .06 + .06 + .06 + .09 \'f03 = = .08 + .06 + .02 + .02 + .01 \'f04 = = .08 + .06 + .02 + .02 + .01 \'f05 = = .08 + .06 + .02 + .02 + .01 \f1\bullet  Example Suppose unit selections are drawn with probability proportional to unit size, and that sampling is done without replacement of units.\par
\endash  The population is the same as the previous example.\par
15\par
1 2 3 4 5\par
yi \f3\u8722?\u8594?\f0  7 4 0 2 3 pi \f3\u8722?\u8594?\f0  .4 .3 .1 .1 .1 \f1\endash  Sampling plan: You are to select two units. The \u-1279?rst unit ui is selected with probability pi proportional to its size and the yi is recorded. The unit is not put back. A second unit uj is selected using sampling proportional to size for the remaining 4 units, and its yj value is recorded. \endash  Note that the same unit cannot be sampled twice. This is an example of sampling without replacement. The following table shows all 10 possible pairs of sampled y\par
values (but not ordered). Note:\par
10 X i=1\par
P(Si) = 315/315 = 1. \endash  Once that once the \u-1279?rst unit is selected, the probabilities for selecting the second unit are no longer pi. The probabilities are proportional to sizes of the remaining 4 units. \endash  For example, to \u-1279?nd the probability of selecting units 1 and 2, we need to calculate the probabilities of (i) selecting unit 1 \u-1279?rst, then unit 2 and (ii) selecting unit 2 \u-1279?rst, then unit 1. \f3\u8727?\f0  The probability of selecting unit 1 \f1\u-1279?rst is .4. Now only units 2, 3, 4, and 5 remain with unit 2 accounting for 3/6 (=.3/(.3+.1+.1+.1) = .3/.6) of the remaining sizes. Thus, the probability of selecting unit 1 then unit 2 = (.4)(.3/.6). \f3\u8727?\f0  The probability of selecting unit 2 \f1\u-1279?rst is .3. Now only units 1, 3, 4, and 5 remain with unit 1 accounting for 4/7 (=.4/(.4+.1+.1+.1) = .4/.7) of the remaining sizes. Thus, the probability of selecting unit 2 then unit 1 = (.3)(.4/.7). \f3\u8727?\f0  Thus, the probability of sampling units 1 and 2 is the sum of these two probabilities: (.4)(.3/.6) + (.3)(.4/.7).\par
Sample Units y-values P(Sj) Calculation S1 \{1,2\} 7 , 4 13/35 = 117/315 \f3\u8776?\f0  .371 (.4)(.3/.6) + (.3)(.4/.7) S2 \{1,3\} 7 , 0 1/9 = 35/315 \f3\u8776?\f0  .111 (.4)(.1/.6) + (.1)(.4/.9) S3 \{1,4\} 7 , 2 1/9 = 35/315 \f3\u8776?\f0  .111 (.4)(.1/.6) + (.1)(.4/.9) S4 \{1,5\} 7 , 3 1/9 = 35/315 \f3\u8776?\f0  .111 (.4)(.1/.6) + (.1)(.4/.9) S5 \{2,3\} 4 , 0 8/105 = 24/315 \f3\u8776?\f0  .076 (.3)(.1/.7) + (.1)(.3/.9) S6 \{2,4\} 4 , 2 8/105 = 24/315 \f3\u8776?\f0  .076 (.3)(.1/.7) + (.1)(.3/.9) S7 \{2,5\} 4 , 3 8/105 = 24/315 \f3\u8776?\f0  .076 (.3)(.1/.7) + (.1)(.3/.9) S8 \{3,4\} 0 , 2 1/45 = 7/315 \f3\u8776?\f0  .022 (.1)(.1/.9) + (.1)(.1/.9) S9 \{3,5\} 0 , 3 1/45 = 7/315 \f3\u8776?\f0  .022 (.1)(.1/.9) + (.1)(.1/.9) S10 \{4,5\} 2 , 3 1/45 = 7/315 \f3\u8776?\f0  .022 (.1)(.1/.9) + (.1)(.1/.9) Thus, the inclusion probabilities when sampling without replacement are \f2\lang1032\'f01 = 74/105 = (117 + 35 + 35 + 35)/315 \f3\u8776?\f0  \f2\lang1032\'f02 = 63/105 = (117 + 24 + 24 + 24)/315 \f3\u8776?\f0  \f2\lang1032\'f03 = 73/315 = (35 + 24 + 7 + 7)/315 \f3\u8776?\f0  \f2\lang1032\'f04 = 73/315 = (35 + 24 + 7 + 7)/315 \f3\u8776?\f0  \f2\lang1032\'f05 = 73/315 = (35 + 24 + 7 + 7)/315 \f3\u8776?\f0  16\par
2.2.1 Parameters, Statistics, Expectations, and Estimation Bias \f1\bullet  One goal of sampling is to draw conclusions about a population of interest based on the data collected. This process of drawing conclusions is called statistical inference. \bullet  A parameter is a value which describes some characteristic of a population (or possibly describes the entire population). \bullet  A statistic is a value that can be computed from the observed (sample) data without making use of any unknown parameters. \bullet  Unless the statistic and parameter are explicitly stated, we will useb \f2\lang1032\'e8 and \'e8 to represent an unspeci\f1\u-1279?ed statistic and parameter of interest, respectively. \bullet  In general, the value of a population parameter is unknown. Statistics computed from sampling data can provide information about the unknown parameter. \bullet  Common statistics of interest: Let y1,y2,...,yn be a sample of y-values.\par
\endash  The sample mean is y =\par
1 n\par
n X i=1\par
yi.\par
\endash  The sample variance is s2 =\par
1 n\f3\u8722?\f0 1\'02(y1 \f3\u8722?\f0 y)2 + (y2 \f3\u8722?\f0 y)2 +\'b7\'b7\'b7+ (yn \f3\u8722?\f0 y)2\'03\par
=\par
1 n\f3\u8722?\f0 1\par
n X i\f3\u8722?\f0 1 (yi \f3\u8722?\f0 y)2 =\par
1 n\f3\u8722?\f0 1\'14Xy2 i \f3\u8722?\f0\par
1 n\'10Xyi\'112\'15\par
\f1\endash  The sample standard deviation s is \f3\u8730?\f0 s2. \f1\bullet  Common parameters of interest: \endash  Notation: Let parameter t be the population total and parameter yU be the population mean from a \u-1279?nite population of size N. Thus,\par
t =\par
N X i=1\par
yi yU =\par
1 N\par
N X i=1\par
yi = (1)\par
\endash  The population variance parameter S2 is de\u-1279?ned as:\par
S2 =\par
1 N \f3\u8722?\f0 1\par
N X i=1\par
(yi \f3\u8722?\f0 yU)2 (2)\par
= \'12 1 N \f3\u8722?\f0 1\'13 N X i=1\par
y2 i \f3\u8722?\f0\par
t2 N! = \'12 1 N \f3\u8722?\f0 1\'13 N X i=1\par
y2 i \f3\u8722?\f0 Ny2 U! \f1\endash  The population standard deviation parameter S is de\u-1279?ned as S = \f3\u8730?\f0 S2. \f1\endash  In other texts, \f2\lang1032\'f4, \f0\lang1033\'b5, \f2\lang1032\'f32 and \'f3 are used to represent the population total t, mean yU, variance S2, and standard deviation S.\par
17\par
\f1\bullet  Because only a part of the population is sampled in any sampling plan, the value of a statisticb \f2\'e8 will vary in repeated random sampling. The inherent variability ofb \'e8 associated with sampling is called sampling variability. \f1\bullet  The sampling distribution of a statisticb \f2\'e8 is the probability distribution of the values that can be observed for the statistic over all possible samples for a given sampling scheme. \f1\bullet  The expected value ofb \f2\'e8, denoted E[b \'e8] is the mean of the sampling distribution ofb \'e8: E[b \'e8] = X S b \'e8SP(S) (3) = X k kP(b \'e8 = k) (4) \f1\endash  In (3): b \f2\'e8S is the value ofb \'e8 calculated for sample S and the summation is taken over all possible samples (S). Thus, E[b \'e8] is the weighted average ofb \'e8 calculated over all possible samples with weights P(S). \f1\endash  In (4): The summation is taken over k = the set of possible values that can be observed forb \f2\'e8. Thus, E[b \'e8] is the weighted average of the possible values ofb \'e8 with weights P(b \'e8 = k) = the probability of observingb \'e8 = k. \f1\endash  These represent two approaches for calculating E[b \f2\'e8]. \f1\bullet  The (estimation) bias of the estimatorb \f2\'e8 for estimating a parameter \'e8 is the numerical di\f1\u-1280?erence between E[b \f2\'e8] and the parameter value \'e8. That is, Bias[b \'e8] = E[b \'e8]\f3\u8722?\f2\lang1032\'e8. \f1\bullet  An estimatorb \f2\'e8 is unbiased to estimate a parameter \'e8 if Bias[b \'e8] = 0. \f1\bullet  Estimation example: Consider the small population of N = 4 values: 0,3,6,12. For this population, the population mean yU = 21/4 = and the population variance\par
S2 =\par
1 N \f3\u8722?\f0 1\par
N X i=1\par
(yi \f3\u8722?\f0 yU)2 =\par
1 3\par
5 X i=1\par
(yi \f3\u8722?\f0 5.25)2\par
=\par
1 3\'02(0\f3\u8722?\f0 5.25)2 + (3\f3\u8722?\f0 5.25)2 + (6\f3\u8722?\f0 5.25)2 + (12\f3\u8722?\f0 5.25)2\'03= 1 3\'02(\f3\u8722?\f0 5.25)2 + (\f3\u8722?\f0 2.25)2 + (0.75)2 + (6.75)2\'03= 1 3 (27.5625 + 5.0625 + 0.5625 + 45.5625) = 78.75 3 = . Thus, S = \f3\u8730?\f0 26.25 \f3\u8776?\f0  . Now, consider the following two sampling schemes, and assume the probabilities for selecting a sampling unit are all equal within each stage. Scheme I: Take a sample of size n = 2 with replacement. Because there are 4\'d74 = 16 ordered sampling sequences, each one has probability = 1/16. See Table 2.1A. Scheme II: Take a sample of size n = 2 without replacement. Because there are 4\'d73 = 12 ordered sampling sequences, each one has probability = 1/12. See Table 2.1B.\par
18\par
Table 2.1A: Sample means, variances, and standard deviations for all possible samples selected with replacement and n = 2 S y-values P(S) yS s2 S sS ySP(S) s2 SP(S) sSP(S) S1 0 , 3 P(S1) = 2/16 1.5 4.5 2.1213 3/16 9/16 0.2652 S2 0 , 6 P(S2) = 2/16 3.0 18.0 4.2426 6/16 36/16 0.5303 S3 0 , 12 P(S3) = 2/16 6.0 72.0 8.4853 12/16 144/16 1.0606 S4 3 , 6 P(S4) = 2/16 4.5 4.5 2.1213 9/16 9/16 0.2652 S5 3 , 12 P(S5) = 2/16 7.5 40.5 6.3640 15/16 81/16 0.7955 S6 6 , 12 P(S6) = 2/16 9.0 18.0 4.2426 18/16 36/16 0.5303 S7 0 , 0 P(S7) = 1/16 0.0 0.0 0 0/16 0/16 0 S8 3 , 3 P(S8) = 1/16 3.0 0.0 0 5/16 0/16 0 S9 6 , 6 P(S9) = 1/16 6.0 0.0 0 6/16 0/16 0 S10 12 , 12 P(S10) = 1/16 12.0 0.0 0 12/16 0/16 0 84/16 315/16 \f3\u8776?\f0  3.4471 Table 2.1B: Sample means, variances, and standard deviations for all possible samples selected without replacement and n = 2 S y-values P(S) yS s2 S sS ySP(S) s2 SP(S) sSP(S) S1 0 , 3 P(S1) = 2/12 1.5 4.5 2.1213 3/12 9/12 0.3536 S2 0 , 6 P(S2) = 2/12 3.0 18.0 4.2426 6/12 36/12 0.7071 S3 0 , 12 P(S3) = 2/12 6.0 72.0 8.4853 12/12 144/12 1.4142 S4 3 , 6 P(S4) = 2/12 4.5 4.5 2.1213 9/12 9/12 0.3536 S5 3 , 12 P(S5) = 2/12 7.5 40.5 6.3640 15/12 81/12 1.0607 S6 6 , 12 P(S6) = 2/12 9.0 18.0 4.2426 18/12 36/12 0.7071 63/12 315/12 \f3\u8776?\f0  4.9497 Estimation using equation (3): \f1\bullet  Recall: the parameter values are yU = 5.25, S2 = 26.25, and S \f3\u8776?\f0  5.1235. \f1\bullet  Using equation (3) and Table 2.1A, we get E[y] = X S ySP(S) = 84/16 = 5.25 \f3\u8722?\u8594?\f0  Bias[y] = 5.25\f3\u8722?\f0 5.25 = (5) E[s2] = X S s2 SP(S) = 315/16 = 19.6875 \f3\u8722?\u8594?\f0  Bias[s2] = 19.6875\f3\u8722?\f0 26.25 = E[s] = X S sSP(S) \f3\u8776?\f0  3.4471 \f3\u8722?\u8594?\f0  Bias[s] \f3\u8776?\f0  3.4471\f3\u8722?\f0 5.1235 = Therefore, y is an unbiased estimator for yU, but s2 and s are biased estimators for S2 for S for Scheme I. \f1\bullet  Using equation (3) and Table 2.1B, we get E[y] = X S ySP(S) = 63/12 = 5.25 \f3\u8722?\u8594?\f0  Bias[y] = 5.25\f3\u8722?\f0 5.25 = (6) E[s2] = X S S2 SP(S) = 315/12 = 26.25 \f3\u8722?\u8594?\f0  Bias[s2] = 315/12\f3\u8722?\f0 26.25 = E[s] = X S sSP(S) \f3\u8776?\f0  4.9497 \f3\u8722?\u8594?\f0  Bias[s] \f3\u8776?\f0  4.9497\f3\u8722?\f0 5.1235 = Therefore, y and s2 are an unbiased estimators for yU and S2, respectively, but s is a biased estimator for S for Scheme II.\par
19\par
Estimation using equation (4):\par
\f1\bullet  To \u-1279?nd the sampling distributions of y, s2, and s, you determine all possible values that can be observed for each statistic and the associated probabilities for observing each of these values. \bullet  Let k represent a possible value of a statistic. \bullet  Tables 2.2A and 2.2B show the sampling distributions of y, s2, and s for Scheme I (sampling with replacement) and II (sampling without replacement), respectively. A third (product) column is included for each statistic to calculate expectations. \bullet  Note that we will get the same results concerning expected values and biases as those summarized in (5) and (6).\par
Table 2.2A: Sampling distribution of y, s2, and s for Scheme I and expected value calculations for E(y), E(s2), and E(s) k P(y = k) kP(y = k) k P(s2 = k) kP(s2 = k) k P(s = k) kP(s = k) 0.0 1/16 0/16 0.0 4/16 0/16 \f3\u8730?\f0 0.0 4/16 0 1.5 2/16 3/16 4.5 4/16 18/16 \f3\u8730?\f0 4.5 4/16 \f3\u8776?\f0  0.5303 3.0 3/16 9/16 18.0 4/16 72/16 \f3\u8730?\f0 18.0 4/16 \f3\u8776?\f0  1.0607 4.5 2/16 9/16 40.5 2/16 81/16 \f3\u8730?\f0 40.5 2/16 \f3\u8776?\f0  0.7955 6.0 3/16 18/16 72.0 2/16 144/16 \f3\u8730?\f0 72.0 2/16 \f3\u8776?\f0  1.0607 7.5 2/16 15/16 9.0 2/16 18/16 12.0 1/16 12/16 E[y] = 84/16 E[S2] = 315/16 E[S] \f3\u8776?\f0\par
Table 2.2B: Sampling distribution of y, s2, and s for Scheme II and expected value calculations for E(y), E(s2), and E(s) k P(y = k) kP(y = k) k P(s2 = k) kP(s2 = k) k P(s = k) kP(s = k) 1.5 2/12 3/12 4.5 4/12 18/12 \f3\u8730?\f0 4.5 4/12 \f3\u8776?\f0  0.7071 3.0 2/12 6/12 18.0 4/12 72/12 \f3\u8730?\f0 18.0 4/12 \f3\u8776?\f0  1.4142 4.5 2/12 9/12 40.5 2/12 81/12 \f3\u8730?\f0 40.5 2/12 \f3\u8776?\f0  1.0607 6.0 2/12 12/12 72.0 2/12 144/12 \f3\u8730?\f0 72.0 2/12 \f3\u8776?\f0  1.4142 7.5 2/12 15/12 9.0 2/12 18/12 E[y] = 63/12 E[S2] = 315/12 E[S] \f3\u8776?\f0  \f1\bullet  Important: You cannot make general statements about bias (such as \ldblquote statisticb \f2\lang1032\'e8 is an unbiased (biased) estimator of parameter \'e8\rdblquote . You must also know the probability sampling plan to determine whether or not a statistic is biased or unbiased. \f1\bullet  For example, it will not always be true that y will be an unbiased estimator of yU. That is, there will be sampling plans for which E(y) 6= yU.\par
20\par
2.2.2 The Variance and Mean Squared Error of a Statistic \bullet  So far the focus has been on the expected value of a statistic to check for bias. Another natural concern is the variability (spread) of the statistic. It is certainly possible for an unbiased statistic to have large variability. \bullet  We will consider two measures of variability: the variance and the mean squared error. \bullet  The variance of the sampling distribution ofb \f2\'e8 (or simply, V (b \'e8)) is de\f1\u-1279?ned to be V (b \f2\'e8) = Eh(b \'e8S \f3\u8722?\f0 E(b \f2\lang1032\'e8))2i = X S P(S)h(b \'e8S \f3\u8722?\f0 E(b \f2\lang1032\'e8)i2 (7) whereb \'e8S is the value ofb \'e8 calculated for sample S. \f1\bullet  The mean squared error is de\u-1279?ned to be MSE[b \f2\'e8] = Eh(b \'e8\f3\u8722?\f2\lang1032\'e8)2i = X S P(S)h(b \'e8S \f3\u8722?\f2\lang1032\'e8)i2 (8)\par
\f1\bullet  The MSE, however, can be rewritten: MSE[b \f2\'e8] = Eh(b \'e8 \f3\u8722?\f0  \f2\lang1032\'e8)2i = E\'14\'10(b \'e8 \f3\u8722?\f0  E[b \f2\lang1032\'e8]) + (E[b \'e8] \f3\u8722?\f0  \f2\lang1032\'e8)\'112\'15 = Eh(b \'e8 \f3\u8722?\f0  E[b \f2\lang1032\'e8])2 + (E[b \'e8] \f3\u8722?\f0  \f2\lang1032\'e8)2 + 2(b \'e8 \f3\u8722?\f0  E[b \f2\lang1032\'e8])(E[b \'e8] \f3\u8722?\f0  \f2\lang1032\'e8)i = Eh(b \'e8 \f3\u8722?\f0  E[b \f2\lang1032\'e8])2i + Eh(E[b \'e8] \f3\u8722?\f0  \f2\lang1032\'e8)2i + 2Eh(b \'e8 \f3\u8722?\f0  E[b \f2\lang1032\'e8])i(E[b \'e8] \f3\u8722?\f0  \f2\lang1032\'e8) = Eh(b \'e8 \f3\u8722?\f0  E[b \f2\lang1032\'e8])2i + Eh(E[b \'e8] \f3\u8722?\f0  \f2\lang1032\'e8)2i + 2(0)(E[b \'e8] \f3\u8722?\f0  \f2\lang1032\'e8) = (9) We used (A + B)2 = A2 + B2 + 2AB with A =b \'e8 \f3\u8722?\f0  E[b \f2\lang1032\'e8] and B = E[b \'e8] \f3\u8722?\f0  \f2\lang1032\'e8. \f1\bullet  The relationship between variance and mean squared error: \endash  The variance is the average of the squared deviations of the statistic values about the mean (expected value) of the statistic. \endash  The mean squared error is the average of the squared deviations of the statistic values about the parameter. \endash  Thus, for an unbiased statistic, the variance and the mean squared error are identical (i.e. V (b\f0\lang9\par
}
 